#!/usr/bin/env python
import os
import json
import sys
import subprocess
from urllib.parse import urljoin

def get_clipboard():
    p = subprocess.Popen(['xclip','-selection', 'clipboard', '-o'], stdout=subprocess.PIPE)
    p.wait()
    d = p.stdout.read()
    return d.decode(encoding="utf-8")
def make_parent_dir(file_path):
    # If parent folders don't exist create them
    if not os.path.exists(os.path.dirname(file_path)):
        try:
            os.makedirs(os.path.dirname(file_path))
        except OSError as exc:  # Guard against race condition
            if exc.errno != errno.EEXIST:
                raise
def save_data(file_path, data):
    # If parent folders don't exist create them
    make_parent_dir(file_path)

    # Write data to file
    with open(file_path, 'wb') as f:
        f.write(data)
def save_sdata(file_path, data):
    # If parent folders don't exist create them
    make_parent_dir(file_path)

    # Write data to file
    with open(file_path, 'w') as f:
        f.write(data)
def load_file(file, defaults="[]"):
    if not os.path.exists(file):
        make_parent_dir(file)
        save_sdata(file, defaults)

    return json.load(open(file))


# Change current dir to HOME
os.chdir(os.path.dirname(sys.argv[0])+"/..")

# GET URL
url = sys.argv[1] if len(sys.argv) >= 2 else get_clipboard()
url = urljoin("http://xcartx.com/", url)

# LOADING JSON
file = "saves/xcart.json"
data = load_file(file, defaults="[]")

# EXTRACT DATA FROM URL
try:
    url_s = url.split("/")
    name = url_s[3].split('.')[0]
except IndexError:
    print("Invalid URL")
    exit(0)

# SET DATA
if name not in data:
    data += [name]

# SAVE
with open(file, 'w') as outfile:
    json.dump(data, outfile, sort_keys=True, indent=4)

# DOWNLOAD
os.system('scrapy crawl xcartx -a name="'+name+'"')
